# üöö Trackr

[![Build Status](https://dev.azure.com/estouro-de-pilha/trackr/_apis/build/status/Backend?branchName=main)](https://dev.azure.com/estouro-de-pilha/trackr/_build/latest?definitionId=3&branchName=main) ![Azure Static Web Apps CI/CD](https://github.com/Jefh-Graduacao/dev3-trackr/workflows/Azure%20Static%20Web%20Apps%20CI/CD/badge.svg)

## Ferramentas para desenvolvimento

| Aplica√ß√£o | Link para download |
| :--- | :--- |
| Docker Desktop | https://www.docker.com/products/docker-desktop |
| IntelliJ IDEA | https://www.jetbrains.com/idea/ |
| JDK 14         | https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html |
| GIT | https://git-scm.com/downloads |
| NodeJS | https://nodejs.org/en/ |
| Yarn | https://yarnpkg.com/ |

### Setup Frontend

Para desenvolvimento _frontend_ √© necess√°rio instalar o [Vue CLI](https://cli.vuejs.org/) e alguns plugins. Para isso, execute o comando abaixo:

```powershell
npm install -g @vue/cli @vue/cli-service-global

# ou

yarn global add @vue/cli @vue/cli-service-global
```

Para instalar as depend√™ncias da aplica√ß√£o, navegue at√© a pasta `frontend` e execute:

```powershell
yarn
```

E, depois, para subir a aplica√ß√£o, execute:

```powershell
yarn serve
```

A sa√≠da deve ser algo parecido com

```none
DONE Compiled successfully in 7353ms
          
No type errors found
Version: typescript 3.9.7
Time: 3179ms

  App running at:
  - Local:   http://localhost:8081/
  - Network: http://192.168.100.4:8081/

  Note that the development build is not optimized.
  To create a production build, run yarn build.
```


## Infraestrutura 

Atualmente o _backend_ usa um [banco de dados em mem√≥ria embutido](https://www.h2database.com/html/main.html), portanto, o setup da infraestrutura n√£o √© necess√°rio para desenvolvimento.

A infraestrutura para desenvolvimento _backend_ (banco de dados) pode ser gerenciada (inicializada, parada e exclu√≠da) usando o Docker. Para isto, navegue at√© a pasta `src/backend` e execute os comandos abaixo:

* Inicializar a infraestrutura (banco de dados e adminer)

    ```powershell
    docker-compose -f .\docker\compose-infra.yml up -d
    ``` 

* Finalizar a infraestrutura

    ```powershell
    docker-compose -f .\docker\compose-infra.yml down
    ```

* Executar a aplica√ß√£o como container

    ```powershell
    docker-compose -f .\docker\compose-infra.yml -f .\docker\compose-backend.yml up -d --build
    ```
    
# Como contribuir
    A Estrutura do backend foi pensada para possibilitar facilmente a expans√£o de novas origem de dados, possuimos suporte para origens de dados que consumam as chaves de 'C√≥digo de rastreio' e 'N√∫mero de documento', sendo que cada um possui um coportamento pr√≥prio.
    ##Por C√≥digo: 
          O front adiciona essa nova op√ß√£o como chave composta nas pesquisas e representa uma busca unit√°ria por encomentas.O c√≥digo pode ser posteriormete vinculado ao documento para que seja consultado tamb√©m quando houver consultas em lote por documento.
    ##Por Documento: 
          Nessa op√ß√£o ser√£o consultados todas as origens de dado por documento para que seja montado o lote de encomendas que ser√° incl√≠do no dashboard.
    
    Para submeter a implementa√ß√£o da nova origem basta que seja enviado o Pull Request seguindo os seguintes passos:
    
    * Primeiramente pensando na nova origem de dados, precisa-se definir se ela √© consumida atrav√©s de um c√≥digo de rastreio ou n√∫mero de documento, em seguida a nova origem de dados deve ser incluida no respectivo **enum**: **TipoCrawlerPorCodigoEnum** ou **TipoCrawlerPorDocumentoEnum**;
    * Ap√≥s isso, no diret√≥rio **crawlers** deve ser criado um novo **service** para a nova origem, toda implementa√ß√£o espec√≠fica dever√° ficar nesse path. O novo **service**
    criado deve implementar a interface correspondente do tipo de origem: **CrawlerCodigo** ou **CrawlerDocumento**;
    * Existe tamb√©m um **service** para orquestrar as origens conforme a entrada, que chamaremos de **orquestrador**, nele deve-se implementar o mapeamento do **enum** de entrada para o **service** criado na etapa anterior, para isso ser√° necess√°rio adicionar o novo **service** como dependencia do **orquestrador** e ent√£o realizar o tratamento no **switch** para a nova origem de dados direcionando para o **service** espec√≠fico, os **orquestradores** espec√≠ficos s√£o: **CrawlerCodigoService** ou **CrawlerDocumentoService**.

    ##Mais
    
    * Apenas ser√£o aceitas contribui√ß√µes conforme os padr√µes de qualidade de c√≥digo, incluindo **testes unit√°rios** e pr√°ticas de **clean code**;
    * Sobre a implementa√ß√£o dos crawlers, utilizamos a biblioteca Jsoup para extrair os dados, mas sinta-se a vontade para utilizar outras.
    
# Outras funcionalidades para contribui√ß√£o
    * Expurgo de rastreios **por c√≥digo** vinculados ao **documento**. Quando √© realizado um vinculo do c√≥digo de rastreio para o documento, toda vez que o documento for consultado esse rastreio vinculado **por c√≥digo** ser√° incluido na resposta, mas algum tempo ap√≥s a entrega do mesmo a informa√ß√£o perde o valor e apenas polui o dashboard;
